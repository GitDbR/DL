{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "577fb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Embedding,Lambda\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e48d209",
   "metadata": {},
   "source": [
    "# a.Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbd6fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"\"\"I love to play Football\",\n",
    "\"Football is a great game\",\n",
    "\"The team played well\",\n",
    "\"Football brings people together\",\n",
    "\"I enjoy watching football matches\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02a665d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love to play Football\",\\n\"Football is a great game\",\\n\"The team played well\",\\n\"Football brings people together\",\\n\"I enjoy watching football matches']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=data.split('.')\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fd26136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love to play football football is a great game the team played well football brings people together i enjoy watching football matches\n"
     ]
    }
   ],
   "source": [
    "clean_sent=[]\n",
    "for sentence in sentences:\n",
    "    if sentence==\"\":\n",
    "        continue\n",
    "    sentence=re.sub('[^A-Za-z0-9]+',' ',(sentence))\n",
    "    sentence=re.sub(r'(?:^| )\\w (?:$| )',' ',(sentence)).strip()\n",
    "    sentence=sentence.lower()\n",
    "    clean_sent.append(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d70017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_sent)\n",
    "sequences=tokenizer.texts_to_sequences(clean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90a82c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'i', 3: 'love', 4: 'to', 5: 'play', 1: 'football', 6: 'is', 7: 'a', 8: 'great', 9: 'game', 10: 'the', 11: 'team', 12: 'played', 13: 'well', 14: 'brings', 15: 'people', 16: 'together', 17: 'enjoy', 18: 'watching', 19: 'matches'} \n",
      "\n",
      "{'i': 2, 'love': 3, 'to': 4, 'play': 5, 'football': 1, 'is': 6, 'a': 7, 'great': 8, 'game': 9, 'the': 10, 'team': 11, 'played': 12, 'well': 13, 'brings': 14, 'people': 15, 'together': 16, 'enjoy': 17, 'watching': 18, 'matches': 19}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}\n",
    "word_to_index={}\n",
    "\n",
    "for i,sequence in enumerate(sequences):\n",
    "    word_in_sentence=clean_sent[i].split()\n",
    "    for j,value in enumerate(sequence):\n",
    "        index_to_word[value]=word_in_sentence[j]\n",
    "        word_to_index[word_in_sentence[j]]=value\n",
    "print(index_to_word,\"\\n\")\n",
    "print(word_to_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08c65e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 5, 1], [3, 4, 1, 1], [4, 5, 1, 6], [5, 1, 6, 7], [1, 1, 7, 8], [1, 6, 8, 9], [6, 7, 9, 10], [7, 8, 10, 11], [8, 9, 11, 12], [9, 10, 12, 13], [10, 11, 13, 1], [11, 12, 1, 14], [12, 13, 14, 15], [13, 1, 15, 16], [1, 14, 16, 2], [14, 15, 2, 17], [15, 16, 17, 18], [16, 2, 18, 1], [2, 17, 1, 19]] \n",
      "\n",
      "[4, 5, 1, 1, 6, 7, 8, 9, 10, 11, 12, 13, 1, 14, 15, 16, 2, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(tokenizer.word_index)+1\n",
    "emb_size=50\n",
    "context_size=2\n",
    "\n",
    "contexts=[]\n",
    "targets=[]\n",
    "\n",
    "for sequence in sequences:\n",
    "    for i in range(context_size,len(sequence)-context_size):\n",
    "        target=sequence[i]\n",
    "        context=[sequence[i-2],\n",
    "                 sequence[i-1],\n",
    "                 sequence[i+1],\n",
    "                 sequence[i+2],\n",
    "                ]\n",
    "        contexts.append(context)\n",
    "        targets.append(target)\n",
    "print(contexts,\"\\n\")\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1376a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'play', 'football'] -> to\n",
      "['love', 'to', 'football', 'football'] -> play\n",
      "['to', 'play', 'football', 'is'] -> football\n",
      "['play', 'football', 'is', 'a'] -> football\n",
      "['football', 'football', 'a', 'great'] -> is\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    words=[]\n",
    "    target=index_to_word.get(targets[i])\n",
    "    for j in contexts[i]:\n",
    "        words.append(index_to_word.get(j))\n",
    "    print(words,\"->\",target)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "048509c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(contexts)\n",
    "Y=np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e209ea2",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73d203c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the CBOW model\n",
    "model= Sequential([\n",
    "    Embedding(input_dim=vocab_size,output_dim=emb_size,input_length=2*context_size),\n",
    "    Lambda(lambda x:tf.reduce_mean(x,axis=1)),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dense(512,activation='relu'),\n",
    "   Dense(vocab_size,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d376fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 2.9950 - accuracy: 0.0000e+00\n",
      "Epoch 2/36\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9851 - accuracy: 0.5789\n",
      "Epoch 3/36\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9759 - accuracy: 0.6316\n",
      "Epoch 4/36\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9666 - accuracy: 0.5263\n",
      "Epoch 5/36\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9565 - accuracy: 0.3684\n",
      "Epoch 6/36\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9451 - accuracy: 0.3684\n",
      "Epoch 7/36\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9321 - accuracy: 0.3684\n",
      "Epoch 8/36\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9176 - accuracy: 0.3158\n",
      "Epoch 9/36\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9013 - accuracy: 0.3158\n",
      "Epoch 10/36\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8829 - accuracy: 0.3158\n",
      "Epoch 11/36\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8625 - accuracy: 0.3158\n",
      "Epoch 12/36\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.8396 - accuracy: 0.2632\n",
      "Epoch 13/36\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8142 - accuracy: 0.2105\n",
      "Epoch 14/36\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7859 - accuracy: 0.2105\n",
      "Epoch 15/36\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7546 - accuracy: 0.2105\n",
      "Epoch 16/36\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7201 - accuracy: 0.2105\n",
      "Epoch 17/36\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6820 - accuracy: 0.2105\n",
      "Epoch 18/36\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6404 - accuracy: 0.2105\n",
      "Epoch 19/36\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5953 - accuracy: 0.2105\n",
      "Epoch 20/36\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5465 - accuracy: 0.2105\n",
      "Epoch 21/36\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4941 - accuracy: 0.2105\n",
      "Epoch 22/36\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4380 - accuracy: 0.2105\n",
      "Epoch 23/36\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3786 - accuracy: 0.2105\n",
      "Epoch 24/36\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3160 - accuracy: 0.2105\n",
      "Epoch 25/36\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2506 - accuracy: 0.2632\n",
      "Epoch 26/36\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1824 - accuracy: 0.2632\n",
      "Epoch 27/36\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1115 - accuracy: 0.3158\n",
      "Epoch 28/36\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0377 - accuracy: 0.3158\n",
      "Epoch 29/36\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9605 - accuracy: 0.3684\n",
      "Epoch 30/36\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8798 - accuracy: 0.4211\n",
      "Epoch 31/36\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7959 - accuracy: 0.4211\n",
      "Epoch 32/36\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7093 - accuracy: 0.4737\n",
      "Epoch 33/36\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6205 - accuracy: 0.6842\n",
      "Epoch 34/36\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5304 - accuracy: 0.7368\n",
      "Epoch 35/36\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4391 - accuracy: 0.8947\n",
      "Epoch 36/36\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3473 - accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model.fit(X,Y,epochs=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a1d0d",
   "metadata": {},
   "source": [
    "# Output(Model Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d8255bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicted word:play\n"
     ]
    }
   ],
   "source": [
    "def predict_word(model,context):\n",
    "    context=np.array(context).reshape(1,-1)\n",
    "    predicted_word=model.predict(context)\n",
    "    return index_to_word[np.argmax(predicted_word)]\n",
    "example_context=[1,2,3,4]\n",
    "predictions=predict_word(model,example_context)\n",
    "print(f'Predicted word:{predictions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4e648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64872235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
